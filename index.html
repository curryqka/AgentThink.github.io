<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AgentThink: A Unified Framework for Toolâ€‘Augmented Chainâ€‘ofâ€‘Thought Reasoning in Visionâ€‘Language Models for Autonomous Driving</title>
  <meta name="description" content="AgentThink project page â€“ toolâ€‘augmented chainâ€‘ofâ€‘thought reasoning framework for autonomous driving VLMs. Demos, results, setup, and citation." />
  <meta property="og:title" content="AgentThink â€“ Toolâ€‘Augmented CoT for Autonomous Driving" />
  <meta property="og:description" content="Demos â€¢ Results â€¢ Quick Start â€¢ Papers â€¢ Code" />
  <meta property="og:type" content="website" />
  <meta name="color-scheme" content="light dark">
  <link rel="icon" href="assets/favicon.png" />
  <style>
    :root{
      --bg: #0b1020; /* dark */
      --card: #11172e;
      --muted: #9fb0c7;
      --text: #eaf1ff;
      --brand: #6aa6ff;
      --brand-2: #a8ffcb;
      --chip: #1e2a4a;
      --ring: #2f3e6e;
      --good: #22c55e; /* green */
      --warn: #f59e0b; /* amber */
      --bad: #ef4444;  /* red */
    }
    @media (prefers-color-scheme: light){
      :root{
        --bg:#f6f7fb;--card:#ffffff;--muted:#50607a;--text:#0d1322;--brand:#2459ff;--brand-2:#0daa6e;--chip:#eef2ff;--ring:#dfe7ff
      }
    }
    *{box-sizing:border-box}
    html,body{margin:0;padding:0;font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji"; color:var(--text); background: radial-gradient(1200px 600px at 70% -10%, rgba(106,166,255,.20), transparent 60%), var(--bg)}
    a{color:var(--brand);text-decoration:none}
    a:hover{text-decoration:underline}
    code, pre{font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace}
    pre{background:var(--card);border:1px solid var(--ring);padding:1rem;border-radius:12px;overflow:auto}
    .container{max-width:1100px;margin:0 auto;padding:20px}
    .header{position:sticky;top:0;backdrop-filter:saturate(1.3) blur(8px);background: color-mix(in oklab, var(--bg), transparent 30%);border-bottom:1px solid var(--ring);z-index:50}
    .header-inner{display:flex;gap:16px;align-items:center;justify-content:space-between;max-width:1100px;margin:0 auto;padding:12px 20px}
    .brand{display:flex;align-items:center;gap:12px}
    .brand img{width:38px;height:38px;border-radius:9px;border:1px solid var(--ring);background:var(--card)}
    .brand h1{font-size:16px;line-height:1.1;margin:0;font-weight:700}
    nav{display:flex;gap:12px;flex-wrap:wrap}
    nav a{padding:7px 10px;background:var(--chip);border:1px solid var(--ring);border-radius:10px}
    .hero{display:grid;grid-template-columns: 1.2fr 0.8fr;gap:24px;align-items:center;margin-top:28px}
    .hero h2{font-size:28px;margin:.2rem 0 1rem}
    .lead{font-size:16px;color:var(--muted)}
    .badges{display:flex;gap:10px;flex-wrap:wrap;margin-top:14px}
    .badge{display:inline-flex;align-items:center;gap:8px;padding:8px 12px;border-radius:999px;background:var(--chip);border:1px solid var(--ring);font-weight:600}
    .pill{display:inline-block;padding:4px 10px;border-radius:999px;border:1px solid var(--ring);background:var(--chip);font-size:13px}
    .quote{padding:14px;border-left:4px solid var(--brand);background:linear-gradient(0deg, color-mix(in oklab, var(--brand), transparent 92%), transparent 92%);border-radius:10px}
    .grid{display:grid;gap:16px}
    .two{grid-template-columns: 1fr 1fr}
    .three{grid-template-columns: repeat(3, 1fr)}
    .card{background:var(--card);border:1px solid var(--ring);border-radius:16px;padding:18px}
    .section{margin:38px 0}
    .section h3{margin:0 0 12px;font-size:22px}
    .section h4{margin:18px 0 8px;font-size:17px}
    .kbd{padding:2px 6px;border:1px solid var(--ring);border-bottom-width:3px;border-radius:6px;background:var(--chip);font-family:inherit}
    table{width:100%;border-collapse:collapse}
    th, td{padding:10px;border-bottom:1px dashed var(--ring);vertical-align:top}
    th{text-align:left}
    .table-wrap{overflow:auto;border:1px solid var(--ring);border-radius:12px}
    .status{font-weight:700}
    .ok{color:var(--good)}.pending{color:var(--warn)}.nope{color:var(--bad)}
    .toc{display:flex;gap:10px;flex-wrap:wrap}
    .toc a{padding:8px 10px;border:1px solid var(--ring);border-radius:10px;background:var(--chip)}
    .lang{display:flex;gap:10px;align-items:center}
    .sr{position:absolute;left:-10000px}
    .footer{margin:50px 0 20px;color:var(--muted);font-size:14px}
    .kbd-row{display:grid;grid-template-columns: 1fr 1fr;gap:16px}
    .mono{font-variant-ligatures:none}
    .top-btn{position:fixed;right:18px;bottom:18px;padding:10px 12px;border-radius:999px;background:var(--brand);color:white;border:none;font-weight:700;cursor:pointer;box-shadow:0 10px 30px rgba(0,0,0,.2)}
    .video{border:1px solid var(--ring);border-radius:12px;overflow:hidden;background:var(--card)}
    .gallery{display:grid;grid-template-columns:repeat(auto-fit, minmax(220px,1fr));gap:12px}
    .gallery a{display:block;text-align:center;padding:10px;border:1px solid var(--ring);border-radius:12px;background:var(--chip)}
    .muted{color:var(--muted)}
  </style>
</head>
<body>
  <header class="header" aria-label="Main navigation">
    <div class="header-inner">
      <div class="brand">
        <img src="assets/AgentThink.png" alt="AgentThink Logo" />
        <h1>AgentThink Â· Toolâ€‘Augmented CoT for Autonomous Driving</h1>
      </div>
      <nav>
        <a href="#highlights">Highlights</a>
        <a href="#updates">Updates</a>
        <a href="#setup">Setup</a>
        <a href="#inference">Inference</a>
        <a href="#results">Results</a>
        <a href="#structure">Repo</a>
        <a href="#license">License</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <section class="hero">
      <div>
        <span class="pill">EMNLP 2025 Findings</span>
        <h2>AgentThink: A Unified Framework for <em>Toolâ€‘Augmented Chainâ€‘ofâ€‘Thought</em> Reasoning in Visionâ€‘Language Models for Autonomous Driving</h2>
        <p class="lead">Contact: <a href="mailto:qka23@mails.tsinghua.edu.cn">qka23@mails.tsinghua.edu.cn</a></p>
        <div class="quote" role="note" aria-label="Xunzi quote">
          <p>ğŸ“œ <strong>â€œA gentleman is not inherently different from others; he excels by skillfully leveraging external tools.â€</strong></p>
          <p class="muted">â€” Xunzi. This philosophy aligns with AgentThink: by orchestrating tools & models, we achieve robust understanding and responses in complex driving scenarios.</p>
        </div>
        <div class="badges" style="margin-top:14px">
          <a class="badge" href="https://github.com/curryqka/AgentThink">ğŸŒ GitHub</a>
          <a class="badge" href="https://arxiv.org/abs/2505.15298" target="_blank" rel="noopener">ğŸ“„ Paper Link</a>
          <a class="badge" href="#updates">ğŸ”– Latest Version v1.1</a>
        </div>
        <div class="lang" style="margin-top:10px">
          <span aria-hidden>ğŸŒ</span>
          <button class="kbd" id="toggle-lang" type="button" title="Toggle page language">ä¸­æ–‡ ï½œ English</button>
        </div>
      </div>
      <div class="card">
        <div class="video">
          <!-- Replace src with your demo video file or YouTube embed -->
          <video src="assets/demo.mp4" controls playsinline poster="assets/demo_poster.jpg" style="width:100%;height:auto"></video>
        </div>
        <p class="muted" style="margin-top:8px">ğŸ¬ Demo Showcase Â· â€œExperience AgentThinkâ€™s perception and planning in complex traffic.â€</p>
      </div>
    </section>

    <section class="section" id="contents">
      <h3>Contents</h3>
      <div class="toc">
        <a href="#highlights">âœ¨ Highlights</a>
        <a href="#updates">ğŸ“° Project Updates</a>
        <a href="#quicknav">ğŸš€ Quick Navigation</a>
        <a href="#setup">âš™ï¸ Getting Started</a>
        <a href="#inference">ğŸš€ Quick Start & Inference</a>
        <a href="#todo">ğŸ“‹ TODO List</a>
        <a href="#results">ğŸ“Š Benchmark & Paper Results</a>
        <a href="#structure">ğŸ“‚ Repository Structure</a>
        <a href="#related">ğŸ”— Related Works</a>
        <a href="#license">ğŸ“œ License & Citation</a>
      </div>
    </section>

    <section class="section" id="demo">
      <h3>ğŸ¬ Demo Showcase</h3>
      <p>Experience AgentThink's realâ€‘world performance through demonstration materials that illustrate its capabilities in autonomous driving scenarios.</p>
      <div class="grid two">
        <div class="card">
          <h4>Video Demonstration</h4>
          <p>Watch this video to see AgentThink's environmental perception in complex traffic conditions:</p>
          <div class="video"><video src="assets/demo.mp4" controls playsinline poster="assets/demo_perception.jpg" style="width:100%"></video></div>
        </div>
        <div class="card">
          <h4>Visualization Gallery</h4>
          <div class="gallery">
            <a href="#" aria-label="Daytime planning">Daytime Planning</a>
            <a href="#" aria-label="Nighttime planning">Nighttime Planning</a>
            <a href="#" aria-label="Zeroâ€‘shot learning">AgentThink zeroâ€‘shot learning</a>
          </div>
          <p class="muted" style="margin-top:8px">Complementing the video, these visualizations demonstrate key capabilities:</p>
          <div class="table-wrap">
            <table>
              <thead><tr><th>Scenario</th><th>Description</th><th>Image</th></tr></thead>
              <tbody>
                <tr><td>Highâ€‘level planning</td><td>Visualizes highâ€‘level planning</td><td><a href="#">View</a></td></tr>
                <tr><td>Spatial Understanding</td><td>Demonstrates spatial relationship analysis</td><td><a href="#">View</a></td></tr>
                <tr><td>Environment Adaptability</td><td>Shows performance in adverse weather or lowâ€‘light</td><td><a href="#">View</a></td></tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </section>

    <section class="section" id="highlights">
      <h3>âœ¨ Highlights</h3>
      <ul>
        <li>ğŸ”§ <strong>Toolâ€‘Augmented Reasoning</strong>: Multiâ€‘modal perception via integrated vision, prediction, occupancy, and mapping tools</li>
        <li>ğŸ§  <strong>Reasoning Chain + Tool Calls</strong>: Task decomposition with explicit tool invocation</li>
        <li>ğŸ¯ <strong>GRPO Training</strong>: Triple reward signals (final answer, stepâ€‘wise, tool usage)</li>
        <li>ğŸš€ <strong>Performance Boost</strong>: <em>53.91% accuracy improvement</em> over traditional VLM models</li>
      </ul>
    </section>

    <section class="section" id="updates">
      <h3>ğŸ“° Project Updates</h3>
      <ul>
        <li>ğŸ‰ <strong>[2025â€‘08â€‘20]</strong> Our paper was accepted as <em>EMNLP 2025 Findings</em></li>
        <li>ğŸš€ <strong>[2025â€‘07â€‘02]</strong> v1.1 released with demo and sample data</li>
        <li>ğŸ“„ <strong>[2025â€‘05â€‘22]</strong> Paper published on arXiv</li>
        <li>ğŸ¥ Web Demo and Swift full training pipeline coming soon</li>
      </ul>
    </section>

    <section class="section" id="quicknav">
      <h3>ğŸš€ Quick Navigation</h3>
      <div class="table-wrap">
        <table>
          <thead><tr><th>Section</th><th>Description</th><th>Link</th></tr></thead>
          <tbody>
            <tr><td>Environment Setup</td><td>Install dependencies and setup</td><td><a href="#setup">Environment Setup</a></td></tr>
            <tr><td>Model Inference</td><td>Realâ€‘time inference on val set</td><td><a href="#inference">Model Inference</a></td></tr>
            <tr><td>Demo Inference</td><td>Run demo on test set</td><td><a href="#demo-infer">Demo Inference</a></td></tr>
            <tr><td>Evaluation Metrics</td><td>Scoring pipeline using LLMâ€‘asâ€‘Judge</td><td><a href="#eval">Evaluation Metrics</a></td></tr>
            <tr><td>Benchmark Results</td><td>Quantitative performance comparisons</td><td><a href="#results">Benchmark Results</a></td></tr>
          </tbody>
        </table>
      </div>
    </section>

    <section class="section" id="setup">
      <h3>âš™ï¸ Getting Started Â· Environment Setup</h3>
      <h4>ğŸ› ï¸ Basic</h4>
      <div class="table-wrap">
        <table>
          <thead><tr><th>Component</th><th>Version</th><th>Command</th></tr></thead>
          <tbody>
            <tr><td>OS</td><td>Ubuntu 20.04</td><td><code>cat /etc/issue</code></td></tr>
            <tr><td>Python</td><td>3.10.12</td><td><code>python --version</code></td></tr>
            <tr><td>CUDA Toolkit</td><td>12.4</td><td><code>nvcc --version</code></td></tr>
            <tr><td>GPU Driver</td><td>535.129.03</td><td><code>nvidia-smi</code></td></tr>
            <tr><td>PyTorch</td><td>2.6.0</td><td><code>print(torch.__version__)</code></td></tr>
          </tbody>
        </table>
      </div>

      <h4>Basic Setup</h4>
      <pre><code class="mono"># Create virtual environment
conda create -n agentthink python=3.10
conda activate agentthink

# Install dependencies
pip install -r requirements.txt

# Install ms-swift
bash scripts/env.sh

# Install drivemllm dependency
bash scripts/env_drivemllm.sh</code></pre>

      <h4>Clone msâ€‘swift</h4>
      <pre><code class="mono">cd third_party
git clone https://github.com/modelscope/ms-swift.git</code></pre>
    </section>

    <section class="section" id="inference">
      <h3>Model Inference</h3>
      <p>ğŸ¬ Use your trained checkpoint <strong>AgentThink</strong> to run inference on val samples <em>AgentThinkâ€‘CoTâ€‘val</em>:</p>
      <pre><code class="mono"># Inference script
bash scripts/inference_scripts/inference.sh [your_CKPT_PATH] [your_OUTPUT_DIR]

# Inference with tool script
bash scripts/inference_scripts/inference_withtool.sh [your_CKPT_PATH] [your_OUTPUT_DIR]

# Inference using multi-node GPUs
bash scripts/inference_scripts/inference_multigpu.sh [your_CKPT_PATH] [your_OUTPUT_DIR]

# Inference AgentThink
bash scripts/inference_agentthink.sh [your_CKPT_PATH] [your_OUTPUT_DIR]</code></pre>
    </section>

    <section class="section" id="eval">
      <h3>Evaluation Metrics</h3>
      <p>ğŸ“Š Use LLMâ€‘asâ€‘Judge to calculate performance metrics:</p>
      <pre><code class="mono"># Evaluate reasoning ability and MCQ accuracy
python evaluation/evaluation_script.py</code></pre>
    </section>

    <section class="section" id="quickstart">
      <h3>ğŸš€ Quick Start</h3>
      <h4>Download the model</h4>
      <p>Our AgentThink model based on the <strong>Qwen2.5â€‘VLâ€‘7B</strong>.</p>

      <h4>Download the tool model</h4>
      <p>Clone the Depth Anything v2 <span class="pill">DAM</span> and YOLOâ€‘World:</p>
      <pre><code class="mono">git clone https://github.com/DepthAnything/Depth-Anything-V2

git clone https://github.com/AILab-CVC/YOLO-World</code></pre>
      <p>Then download the pretrain models in the YOLOâ€‘World and DepthAnything.</p>

      <h4>Download the basic tool results</h4>
      <p>Download the <code>val.pkl</code> file from <a href="https://github.com/USC-GVL/Agent-Driver" target="_blank" rel="noopener">USCâ€‘GVL / Agentâ€‘Driver</a>.</p>

      <h4>Folder structure</h4>
      <pre><code class="mono">AgentThink/
â”œâ”€â”€ ğŸ“‚ data/                    # Dataset and processed data
â”‚   â”œâ”€â”€ DriveLMMo1_TEST_tool_results.jsonl
â”‚   â”œâ”€â”€ DriveLMMo1_TEST.jsonl
â”‚   â”œâ”€â”€ ğŸ“‚ image2concat/        # Concatenated image files
â”‚   â””â”€â”€ ğŸ“‚ tool_results/        # Results from tool processing
â”‚
â”œâ”€â”€ ğŸ“‚ demo_image/              # Demonstration images
â”‚   â”œâ”€â”€ nuscenes_CAM_FRONT_3590.webp
â”‚   â”œâ”€â”€ nuscenes_CAM_FRONT_3757.webp
â”‚   â””â”€â”€ nuscenes_CAM_FRONT_3896.webp
â”‚
â”œâ”€â”€ ğŸ“‚ pretrained_model/        # Pre-trained model files
â”‚   â”œâ”€â”€ ğŸ“‚ AgentThink/
â”‚   â”‚   â””â”€â”€ checkpoint-700-merged
â”‚   â”œâ”€â”€ depth_anything_v2_vitb.pth
â”‚   â””â”€â”€ yolov8x-world2.pt
â”‚
â”œâ”€â”€ ğŸ“‚ assets/                  # Visual assets and resources
â”œâ”€â”€ ğŸ“‚ evaluation/              # Evaluation scripts and benchmarks
â”œâ”€â”€ ğŸ“‚ Inference/               # Inference-related scripts and data
â”œâ”€â”€ ğŸ“‚ results/                 # Output and result files
â”œâ”€â”€ ğŸ“‚ scripts/                 # Various utility scripts
â”œâ”€â”€ ğŸ“‚ third_party/             # Third-party libraries and resources
â”œâ”€â”€ README.cn.md                # Chinese documentation
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ ...                         # Other project files</code></pre>
    </section>

    <section class="section" id="demo-infer">
      <h3>Demo Inference</h3>
      <pre><code class="mono"># drivemllm
python Inference/inference_demo_drivemllm.py

# drivelmm-o1
python Inference/inference_demo_drivelmm.py</code></pre>
    </section>

    <section class="section" id="todo">
      <h3>ğŸ“‹ TODO List Â· Development Roadmap</h3>
      <div class="table-wrap">
        <table>
          <thead><tr><th>Status</th><th>Task Description</th></tr></thead>
          <tbody>
            <tr><td class="status ok">âœ…</td><td>AgentThink demo implementation</td></tr>
            <tr><td class="status ok">âœ…</td><td>General reasoning evaluation metrics</td></tr>
            <tr><td class="status pending">ğŸ”œ</td><td>Toolâ€‘specific evaluation metrics</td></tr>
            <tr><td class="status pending">ğŸ”œ</td><td>Data preprocessing pipeline</td></tr>
            <tr><td class="status ok">âœ…</td><td>Debug example implementation</td></tr>
            <tr><td class="status pending">ğŸ”œ</td><td>Multiâ€‘stage training framework</td></tr>
            <tr><td class="status pending">ğŸ”œ</td><td>Tool function interaction environment</td></tr>
          </tbody>
        </table>
      </div>
    </section>

    <section class="section" id="results">
      <h3>AgentThink Results</h3>

      <h4>ğŸ“Š DriveLMMâ€‘o1 Performance</h4>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Vision Language Models</th>
              <th>Risk Assess. (%) â†‘</th>
              <th>Rule Adh. (%) â†‘</th>
              <th>Scene Aware. (%) â†‘</th>
              <th>Relevance (%) â†‘</th>
              <th>Missing (%) â†‘</th>
              <th>Reason. (%) â†‘</th>
              <th>MCQ (%) â†‘</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>GPTâ€‘4o [16]</td><td>71.32</td><td>80.72</td><td>72.96</td><td>76.65</td><td>71.43</td><td>72.52</td><td>57.84</td></tr>
            <tr><td>Ovis1.5â€‘Gemma2â€‘9B [21]</td><td>51.34</td><td>66.36</td><td>54.74</td><td>55.72</td><td>55.74</td><td>55.62</td><td>48.85</td></tr>
            <tr><td>Mulberryâ€‘7B [45]</td><td>51.89</td><td>63.66</td><td>56.68</td><td>57.27</td><td>57.45</td><td>57.65</td><td>52.86</td></tr>
            <tr><td>LLaVAâ€‘CoT [43]</td><td>57.62</td><td>69.01</td><td>60.84</td><td>62.72</td><td>60.67</td><td>61.41</td><td>49.27</td></tr>
            <tr><td>LlamaVâ€‘o1 [34]</td><td>60.20</td><td>73.52</td><td>62.67</td><td>64.66</td><td>63.41</td><td>63.13</td><td>50.02</td></tr>
            <tr><td>InternVL2.5â€‘8B [4]</td><td>69.02</td><td>78.43</td><td>71.52</td><td>75.80</td><td>70.54</td><td>71.62</td><td>54.87</td></tr>
            <tr><td>Qwen2.5â€‘VLâ€‘7B [1]</td><td>46.44</td><td>60.45</td><td>51.02</td><td>50.15</td><td>52.19</td><td>51.77</td><td>37.81</td></tr>
            <tr><td>DriveLMMâ€‘o1 [15]</td><td>73.01</td><td>81.56</td><td>75.39</td><td>79.42</td><td>74.49</td><td>75.24</td><td>62.36</td></tr>
            <tr><td><strong>AgentThink (Ours)</strong></td><td><strong>80.51</strong></td><td><strong>84.98</strong></td><td><strong>82.11</strong></td><td><strong>84.99</strong></td><td><strong>79.56</strong></td><td><strong>79.68</strong></td><td><strong>71.35</strong></td></tr>
          </tbody>
        </table>
      </div>

      <h4 style="margin-top:24px">ğŸ“Š DriveMLLM Comparison</h4>
      <div class="table-wrap">
        <table>
          <thead>
            <tr>
              <th>Type</th><th>Model</th><th>L/R</th><th>F/B</th><th>RHD</th><th>RD</th><th>PPos</th><th>BBox</th><th>CVD</th><th>CD</th><th>AccS</th><th>Overall</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Zeroâ€‘shot</td><td>GPTâ€‘4o [16]</td><td>91.72</td><td>67.60</td><td>9.58</td><td>14.69</td><td>40.90</td><td>4.07</td><td>46.11</td><td>70.65</td><td>43.16</td><td>25.63</td></tr>
            <tr><td>Zeroâ€‘shot</td><td>GPTâ€‘4oâ€‘mini</td><td>67.67</td><td>50.13</td><td>70.44</td><td>0.00</td><td>29.28</td><td>3.78</td><td>0.00</td><td>46.40</td><td>33.46</td><td>16.68</td></tr>
            <tr><td>Zeroâ€‘shot</td><td>LLaVAâ€‘ovâ€‘72B [19]</td><td>85.42</td><td>49.48</td><td>13.76</td><td>45.27</td><td>16.46</td><td>0.00</td><td>42.97</td><td>27.09</td><td>35.06</td><td>21.10</td></tr>
            <tr><td>Zeroâ€‘shot</td><td>Qwen2.5â€‘VLâ€‘7B [1]</td><td>76.55</td><td>55.24</td><td>7.14</td><td>17.11</td><td>55.97</td><td>38.31</td><td>55.94</td><td>51.52</td><td>44.72</td><td>13.36</td></tr>
            <tr><td>Zeroâ€‘shot</td><td>Qwen + CoT</td><td>87.06</td><td>63.09</td><td>16.69</td><td>22.56</td><td>52.51</td><td>38.87</td><td>76.90</td><td>38.71</td><td>49.55</td><td>19.31</td></tr>
            <tr><td>Zeroâ€‘shot</td><td>Qwen + DirectTool</td><td>78.95</td><td>48.96</td><td>58.43</td><td>67.57</td><td>58.20</td><td>42.22</td><td>51.76</td><td>51.38</td><td>57.18</td><td>24.05</td></tr>
            <tr><td>Zeroâ€‘shot</td><td><strong>AgentThink (Ours)</strong></td><td>82.33</td><td>54.40</td><td>56.14</td><td>61.45</td><td>70.45</td><td>56.23</td><td>23.09</td><td>51.60</td><td>56.96</td><td>26.52</td></tr>
            <tr><td>Oneâ€‘shot</td><td>GPTâ€‘4o</td><td>91.08</td><td>69.37</td><td>36.51</td><td>71.17</td><td>42.44</td><td>5.10</td><td>0.00</td><td>63.88</td><td>47.44</td><td>33.17</td></tr>
            <tr><td>Oneâ€‘shot</td><td>GPTâ€‘4oâ€‘mini</td><td>66.00</td><td>48.95</td><td>83.02</td><td>58.47</td><td>25.71</td><td>3.97</td><td>52.73</td><td>55.23</td><td>49.26</td><td>22.13</td></tr>
            <tr><td>Oneâ€‘shot</td><td>LLaVAâ€‘ovâ€‘72B [19]</td><td>79.12</td><td>62.97</td><td>49.26</td><td>68.04</td><td>28.57</td><td>2.20</td><td>53.12</td><td>60.90</td><td>50.52</td><td>36.66</td></tr>
            <tr><td>Oneâ€‘shot</td><td>Qwen2.5â€‘VLâ€‘7B [1]</td><td>80.30</td><td>53.14</td><td>36.96</td><td>39.13</td><td>62.69</td><td>22.63</td><td>49.88</td><td>48.32</td><td>49.13</td><td>33.53</td></tr>
            <tr><td>Oneâ€‘shot</td><td>Qwen + CoT</td><td>86.35</td><td>59.95</td><td>43.29</td><td>31.81</td><td>53.64</td><td>26.93</td><td>51.02</td><td>42.30</td><td>49.41</td><td>32.06</td></tr>
            <tr><td>Oneâ€‘shot</td><td>Qwen + DirectTool</td><td>84.57</td><td>55.50</td><td>67.32</td><td>59.54</td><td>85.58</td><td>26.07</td><td>52.34</td><td>53.25</td><td>60.52</td><td>42.27</td></tr>
            <tr><td>Oneâ€‘shot</td><td><strong>AgentThink (Ours)</strong></td><td>78.71</td><td>48.46</td><td>60.64</td><td>60.71</td><td>72.36</td><td>64.46</td><td>52.26</td><td>52.04</td><td>61.21</td><td><strong>47.24</strong></td></tr>
          </tbody>
        </table>
      </div>
    </section>

    <section class="section" id="structure">
      <h3>ğŸ“ Repository Structure</h3>
      <pre><code class="mono">AgentThink/
â”œâ”€â”€ assets/                 # Visual assets and resources
â”œâ”€â”€ data/                   # Data files and datasets
â”œâ”€â”€ evaluation/             # Evaluation scripts and benchmarks
â”‚   â”œâ”€â”€ evaluation_script.py
â”‚   â””â”€â”€ inference_agentthink.py
â”œâ”€â”€ Inference/              # Inference-related scripts and data
â”‚   â”œâ”€â”€ inference_demo_data_drivemllm.json
â”‚   â”œâ”€â”€ inference_demo_data_drivelmm.json
â”‚   â””â”€â”€ inference_demo_drivemllm.py
â”œâ”€â”€ results/                # Output and result files
â”‚   â””â”€â”€ agentthink/
â”œâ”€â”€ scripts/                # Various utility scripts
â”‚   â”œâ”€â”€ debug_scripts/
â”‚   â”œâ”€â”€ inference_scripts/
â”‚   â””â”€â”€ tools/              # Tool library implementations
â”œâ”€â”€ third_party/            # Third-party libraries and resources
â”‚   â”œâ”€â”€ ğŸ inference.py         # Main inference script
â”‚   â”œâ”€â”€ ğŸ prepare_data.py      # Data preparation script
â”‚   â”œâ”€â”€ ğŸ utlis.py             # Utility functions
â”‚   â”œâ”€â”€ ğŸš env.sh               # Environment setup script
â”‚   â”œâ”€â”€ ğŸš env_drivemllm.sh     # DriveMLLM environment script
â”‚   â””â”€â”€ ğŸš prepare_json_data.sh # Long JSON data preparation script
â”œâ”€â”€ ğŸ“„ README.md            # Project documentation
â”œâ”€â”€ ğŸ“„ README_CN.md         # ä¸­æ–‡æ–‡æ¡£
â”œâ”€â”€ ğŸ“„ requirements.txt     # Python dependencies</code></pre>
    </section>

    <section class="section" id="related">
      <h3>ğŸ”— Related Works</h3>
      <div class="table-wrap">
        <table>
          <thead><tr><th>Name</th><th>Description</th><th>Link</th></tr></thead>
          <tbody>
            <tr><td>Depthâ€‘Anythingâ€‘V2</td><td>Highâ€‘quality monocular depth estimation</td><td><a href="https://github.com/DepthAnything/Depth-Anything-V2" target="_blank" rel="noopener">GitHub</a></td></tr>
            <tr><td>YOLOâ€‘World</td><td>Openâ€‘vocabulary object detection</td><td><a href="https://github.com/AILab-CVC/YOLO-World" target="_blank" rel="noopener">GitHub</a></td></tr>
            <tr><td>allâ€‘MiniLM</td><td>Extract language semantic similarity</td><td><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noopener">HuggingFace</a></td></tr>
            <tr><td>AgentDriver</td><td>Offer the tool results</td><td><a href="https://github.com/USC-GVL/Agent-Driver" target="_blank" rel="noopener">GitHub</a></td></tr>
          </tbody>
        </table>
      </div>
    </section>

    <section class="section" id="license">
      <h3>ğŸªª License & Citation</h3>
      <h4>License</h4>
      <p>This project is licensed under <strong>Apache License 2.0</strong>. See <code>LICENSE</code> file for details.</p>

      <h4>Citation</h4>
      <pre><code class="mono">@misc{qian2025agentthinkunifiedframeworktoolaugmented,
  title={AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving},
  author={Kangan Qian et al.},
  year={2025},
  eprint={2505.15298},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2505.15298},
}</code></pre>
    </section>

<footer class="footer">
<p>Â© <span id="year"></span> AgentThink Team Â·
<a href="mailto:qka23@mails.tsinghua.edu.cn">qka23@mails.tsinghua.edu.cn</a> Â·
<a href="mailto:sicong.jiang@mail.mcgill.ca">sicong.jiang@mail.mcgill.ca</a>
</p>
</footer>
</main>

  <button class="top-btn" onclick="window.scrollTo({top:0, behavior:'smooth'})" aria-label="Back to top">â†‘</button>

  <script>
    // Year stamp
    document.getElementById('year').textContent = new Date().getFullYear();

    // Simple language toggle (stub)
    document.getElementById('toggle-lang').addEventListener('click', () => {
      const isCN = document.documentElement.lang === 'zh-CN';
      document.documentElement.lang = isCN ? 'en' : 'zh-CN';
      alert('Language toggled. (This is a placeholder. Replace with real i18n if needed.)');
    });
  </script>
</body>
</html>
